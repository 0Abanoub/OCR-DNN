# Ø´Ø±Ø­ Ù…Ø´Ø±ÙˆØ¹ OCR CNN Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

---

## ğŸ“š Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª

1. [Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹](#overview)
2. [Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª](#imports)
3. [Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ØªÙƒÙˆÙŠÙ†](#config)
4. [ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª](#data)
5. [Ø¨Ù†ÙŠØ© Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©](#model)
6. [Ø§Ù„ØªØ¯Ø±ÙŠØ¨](#training)
7. [Ø§Ù„ØªÙ‚ÙŠÙŠÙ…](#evaluation)
8. [Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤](#inference)
9. [Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©](#mistakes)
10. [Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª](#best-practices)
11. [Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©](#improvements)
12. [Ù…Ù„Ø®Øµ Pipeline](#pipeline)
13. [Ù†Ø­Ùˆ Ù†Ø¸Ø§Ù… OCR Ø¥Ù†ØªØ§Ø¬ÙŠ](#production)

---

## 1. Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ {#overview}

### ğŸ¯ Ø§Ù„Ù‡Ø¯Ù
Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙŠÙ‡Ø¯Ù Ù„Ø¨Ù†Ø§Ø¡ Ù†Ø¸Ø§Ù… **Optical Character Recognition (OCR)** Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **Convolutional Neural Network (CNN)** Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø­Ø±Ù ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (0-9, A-Z).

### ğŸ“Š Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- **Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª**: 36 ÙØ¦Ø© (10 Ø£Ø±Ù‚Ø§Ù… + 26 Ø­Ø±Ù)
- **Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨**: 20,529 ØµÙˆØ±Ø©
- **Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±**: 1,008 ØµÙˆØ±Ø©
- **Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©**: 64Ã—64 Ø¨ÙƒØ³Ù„ (grayscale)

### ğŸ—ï¸ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
```
Input (64Ã—64Ã—1) â†’ Conv1 (32 filters) â†’ MaxPool â†’ Conv2 (64 filters) â†’ MaxPool â†’ FC1 (256) â†’ FC2 (36)
```

---

## 2. Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª {#imports}

### ğŸ“¦ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©

```python
import os
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tqdm.auto import tqdm
```

#### Ø§Ù„Ø´Ø±Ø­:
- **`os` Ùˆ `Path`**: Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ù…Ù„ÙØ§Øª
- **`numpy`**: Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª
- **`matplotlib`**: Ù„Ø±Ø³Ù… Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
- **`PIL.Image`**: Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
- **`tqdm`**: Ù„Ø¹Ø±Ø¶ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù… Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨

### ğŸ”¥ Ù…ÙƒØªØ¨Ø§Øª PyTorch

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import torchvision.datasets as datasets
```

#### Ø§Ù„Ø´Ø±Ø­:
- **`torch`**: Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù€ PyTorch
- **`nn`**: ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©
- **`F`**: Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© (Ù…Ø«Ù„ softmax, relu)
- **`optim`**: Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ† (Adam, SGD, etc.)
- **`DataLoader`**: Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª (batches)
- **`transforms`**: Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ± (resize, normalize, augmentation)

### ğŸŒ± Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨Ø°ÙˆØ± Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©

```python
torch.manual_seed(42)
np.random.seed(42)
```

#### Ù„Ù…Ø§Ø°Ø§ØŸ
- **Reproducibility**: Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©
- Ø§Ù„Ù‚ÙŠÙ…Ø© 42 Ù‡ÙŠ Ù…Ø¬Ø±Ø¯ Ø§ØªÙØ§Ù‚ Ø´Ø§Ø¦Ø¹ (Ù…Ù† "The Hitchhiker's Guide to the Galaxy")

#### Ù…Ø§Ø°Ø§ Ù„Ùˆ Ù„Ù… Ù†ÙØ¹Ù„ Ø°Ù„ÙƒØŸ
- Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø³ØªØ®ØªÙ„Ù ÙÙŠ ÙƒÙ„ ØªØ´ØºÙŠÙ„
- ØµØ¹ÙˆØ¨Ø© ÙÙŠ debugging ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬

---

## 3. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ØªÙƒÙˆÙŠÙ† {#config}

### âš™ï¸ Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ØªÙƒÙˆÙŠÙ†

```python
CONFIG = {
    'data_dir': r'D:\...\data',
    'train_dir': 'training_data',
    'test_dir': 'testing_data',
    'img_size': 64,
    'batch_size': 32,
    'num_epochs': 10,
    'learning_rate': 0.001,
    'use_augmentation': False,
    'num_workers': 2,
    'pin_memory': True,
    'device': 'cuda' if torch.cuda.is_available() else 'cpu'
}
```

### ğŸ“ Ø´Ø±Ø­ ÙƒÙ„ Ù…Ø¹Ø§Ù…Ù„:

#### `img_size: 64`
- **Ù…Ø§Ø°Ø§**: Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ø¬ÙŠÙ…
- **Ù„Ù…Ø§Ø°Ø§**: ØªÙˆØ­ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ù„Ù„Ø´Ø¨ÙƒØ©
- **Ø§Ù„ØªØ£Ø«ÙŠØ±**: ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯ Ø§Ù„Ø­Ø¬Ù…ØŒ Ø²Ø§Ø¯Øª Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ù„ÙƒÙ† Ø²Ø§Ø¯ Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠ

#### `batch_size: 32`
- **Ù…Ø§Ø°Ø§**: Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± ÙÙŠ ÙƒÙ„ Ø¯ÙØ¹Ø©
- **Ù„Ù…Ø§Ø°Ø§**: 
  - Batch ÙƒØ¨ÙŠØ± â†’ Ø°Ø§ÙƒØ±Ø© Ø£ÙƒØ«Ø±ØŒ ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø±Ø¹ØŒ Ù„ÙƒÙ† Ù‚Ø¯ ÙŠØ¤Ø¯ÙŠ Ù„Ù€ overfitting
  - Batch ØµØºÙŠØ± â†’ Ø°Ø§ÙƒØ±Ø© Ø£Ù‚Ù„ØŒ ØªØ¯Ø±ÙŠØ¨ Ø£Ø¨Ø·Ø£ØŒ Ù„ÙƒÙ† generalization Ø£ÙØ¶Ù„
- **Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø«Ù„Ù‰**: 32-64 Ø¹Ø§Ø¯Ø©Ù‹ Ù…Ù†Ø§Ø³Ø¨Ø©

#### `learning_rate: 0.001`
- **Ù…Ø§Ø°Ø§**: Ø­Ø¬Ù… Ø§Ù„Ø®Ø·ÙˆØ© ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†
- **Ù„Ù…Ø§Ø°Ø§**: 
  - ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹ â†’ Ù‚Ø¯ Ù„Ø§ ÙŠØªÙ‚Ø§Ø±Ø¨ (diverge)
  - ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ â†’ ØªØ¯Ø±ÙŠØ¨ Ø¨Ø·ÙŠØ¡ Ø¬Ø¯Ø§Ù‹
- **0.001**: Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¬ÙŠØ¯Ø© Ù„Ù€ Adam optimizer

#### `use_augmentation: False`
- **Ù…Ø§Ø°Ø§**: ØªÙØ¹ÙŠÙ„/ØªØ¹Ø·ÙŠÙ„ Data Augmentation
- **Ù„Ù…Ø§Ø°Ø§**: 
  - True â†’ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙ†ÙˆØ¹ØŒ ÙŠÙ‚Ù„Ù„ overfitting
  - False â†’ Ø£Ø³Ø±Ø¹ØŒ Ù„ÙƒÙ† Ù‚Ø¯ ÙŠØ­Ø¯Ø« overfitting
- **ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹**: Ù…Ø¹Ø·Ù„ Ù„Ø£Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©

#### `num_workers: 2`
- **Ù…Ø§Ø°Ø§**: Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ© Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- **Ù„Ù…Ø§Ø°Ø§**: ØªØ³Ø±ÙŠØ¹ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- **Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø«Ù„Ù‰**: 2-4 Ø¹Ø§Ø¯Ø©Ù‹

#### `pin_memory: True`
- **Ù…Ø§Ø°Ø§**: ØªØ«Ø¨ÙŠØª Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù†Ù‚Ù„ Ø£Ø³Ø±Ø¹ Ù„Ù„Ù€ GPU
- **Ù„Ù…Ø§Ø°Ø§**: ÙŠØ³Ø±Ø¹ Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† CPU Ø¥Ù„Ù‰ GPU
- **Ù…ØªÙ‰**: ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… CUDA

---

## 4. ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª {#data}

### ğŸ”„ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª (Transformations)

```python
base_transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.Grayscale(num_output_channels=1),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
```

#### Ø´Ø±Ø­ ÙƒÙ„ Ø®Ø·ÙˆØ©:

##### 1. `Resize((64, 64))`
- **Ù…Ø§Ø°Ø§**: ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ 64Ã—64
- **Ù„Ù…Ø§Ø°Ø§**: ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø­Ø¬Ø§Ù…
- **ÙƒÙŠÙ**: Interpolation (Ø¹Ø§Ø¯Ø©Ù‹ bilinear)

##### 2. `Grayscale(num_output_channels=1)`
- **Ù…Ø§Ø°Ø§**: ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ grayscale
- **Ù„Ù…Ø§Ø°Ø§**: 
  - OCR Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Ø£Ù„ÙˆØ§Ù†
  - ÙŠÙ‚Ù„Ù„ Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠ (1 channel Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 3)
- **ÙƒÙŠÙ**: `Gray = 0.299*R + 0.587*G + 0.114*B`

##### 3. `ToTensor()`
- **Ù…Ø§Ø°Ø§**: ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† PIL Image Ø¥Ù„Ù‰ PyTorch Tensor
- **ÙƒÙŠÙ**: 
  - Ù…Ù† [0, 255] Ø¥Ù„Ù‰ [0, 1]
  - Ù…Ù† (H, W, C) Ø¥Ù„Ù‰ (C, H, W)

##### 4. `Normalize((0.5,), (0.5,))`
- **Ù…Ø§Ø°Ø§**: ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ…
- **ÙƒÙŠÙ**: `output = (input - mean) / std`
- **Ø§Ù„Ù†ØªÙŠØ¬Ø©**: Ù…Ù† [0, 1] Ø¥Ù„Ù‰ [-1, 1]
- **Ù„Ù…Ø§Ø°Ø§**: 
  - ÙŠØ³Ø±Ø¹ Ø§Ù„ØªÙ‚Ø§Ø±Ø¨
  - ÙŠØ­Ø³Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ø¹Ø¯Ø¯ÙŠ
  - ÙŠØ³Ø§Ø¹Ø¯ ÙÙŠ ØªØ¬Ù†Ø¨ vanishing/exploding gradients

### ğŸ“Š Data Augmentation (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

```python
if CONFIG['use_augmentation']:
    train_transform = transforms.Compose([
        transforms.Resize((64, 64)),
        transforms.Grayscale(num_output_channels=1),
        transforms.RandomRotation(10),
        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
```

#### ØªÙ‚Ù†ÙŠØ§Øª Augmentation:

##### `RandomRotation(10)`
- **Ù…Ø§Ø°Ø§**: Ø¯ÙˆØ±Ø§Ù† Ø¹Ø´ÙˆØ§Ø¦ÙŠ Â±10 Ø¯Ø±Ø¬Ø§Øª
- **Ù„Ù…Ø§Ø°Ø§**: Ø§Ù„Ø£Ø­Ø±Ù Ù‚Ø¯ ØªÙƒÙˆÙ† Ù…Ø§Ø¦Ù„Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹
- **Ø§Ù„ØªØ£Ø«ÙŠØ±**: ÙŠØ²ÙŠØ¯ Ø§Ù„ØªÙ†ÙˆØ¹ØŒ ÙŠÙ‚Ù„Ù„ overfitting

##### `RandomAffine(degrees=0, translate=(0.1, 0.1))`
- **Ù…Ø§Ø°Ø§**: Ø¥Ø²Ø§Ø­Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© 10% ÙÙŠ Ø£ÙŠ Ø§ØªØ¬Ø§Ù‡
- **Ù„Ù…Ø§Ø°Ø§**: Ø§Ù„Ø£Ø­Ø±Ù Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† ÙÙŠ Ø§Ù„Ù…Ø±ÙƒØ² ØªÙ…Ø§Ù…Ø§Ù‹
- **Ø§Ù„ØªØ£Ø«ÙŠØ±**: ÙŠØ¬Ø¹Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙƒØ«Ø± robustness

### ğŸ—‚ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

```python
train_dataset = datasets.ImageFolder(
    CONFIG['train_path'],
    transform=train_transform
)
```

#### ÙƒÙŠÙ ÙŠØ¹Ù…Ù„ `ImageFolder`ØŸ
```
data/
â”œâ”€â”€ training_data/
â”‚   â”œâ”€â”€ 0/
â”‚   â”‚   â”œâ”€â”€ img1.png
â”‚   â”‚   â”œâ”€â”€ img2.png
â”‚   â”œâ”€â”€ 1/
â”‚   â”‚   â”œâ”€â”€ img1.png
â”‚   â”œâ”€â”€ A/
â”‚   â”‚   â”œâ”€â”€ img1.png
â”‚   â”œâ”€â”€ B/
â”‚   â”‚   â”œâ”€â”€ img1.png
```

- **Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©**: Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ = Label
- **Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¨Ø¬Ø¯ÙŠ**: ['0', '1', ..., '9', 'A', 'B', ..., 'Z']

### ğŸ”¢ DataLoader

```python
train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=2,
    pin_memory=True
)
```

#### Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:

- **`shuffle=True`**: Ø®Ù„Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ ÙƒÙ„ epoch
  - **Ù„Ù…Ø§Ø°Ø§**: ÙŠÙ…Ù†Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† ØªØ¹Ù„Ù… ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
  - **Ù…ØªÙ‰**: ÙÙ‚Ø· Ù„Ù„ØªØ¯Ø±ÙŠØ¨ (Ù„ÙŠØ³ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±)

- **`num_workers=2`**: Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
  - **Ù„Ù…Ø§Ø°Ø§**: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
  - **Ø§Ù„ØªØ£Ø«ÙŠØ±**: ÙŠÙ‚Ù„Ù„ ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±

---

## 5. Ø¨Ù†ÙŠØ© Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ© {#model}

### ğŸ—ï¸ Ù…Ø¹Ù…Ø§Ø±ÙŠØ© CNN

```python
class OCRCNN(nn.Module):
    def __init__(self, num_classes):
        super(OCRCNN, self).__init__()
        
        # Convolutional layers
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        
        # Pooling layer
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # Fully connected layers
        self.fc1 = nn.Linear(64 * 16 * 16, 256)
        self.fc2 = nn.Linear(256, num_classes)
        
        # Dropout
        self.dropout = nn.Dropout(0.5)
```

### ğŸ“ Ø´Ø±Ø­ ÙƒÙ„ Ø·Ø¨Ù‚Ø©:

#### Conv2d Layer 1
```python
self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
```

**Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ:**
- **Filter/Kernel**: Ù…ØµÙÙˆÙØ© 3Ã—3 ØªØªØ­Ø±Ùƒ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©
- **Convolution**: Ø¶Ø±Ø¨ element-wise Ø«Ù… Ø¬Ù…Ø¹
- **Output**: Feature map ØªÙƒØªØ´Ù patterns Ù…Ø¹ÙŠÙ†Ø©

**Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:**
- `in_channels=1`: ØµÙˆØ±Ø© grayscale (Ù‚Ù†Ø§Ø© ÙˆØ§Ø­Ø¯Ø©)
- `out_channels=32`: 32 filter Ù…Ø®ØªÙ„Ù
- `kernel_size=3`: Ø­Ø¬Ù… Ø§Ù„Ù€ filter (3Ã—3)
- `padding=1`: Ø¥Ø¶Ø§ÙØ© ØµÙ/Ø¹Ù…ÙˆØ¯ Ù…Ù† Ø§Ù„Ø£ØµÙØ§Ø± Ø­ÙˆÙ„ Ø§Ù„ØµÙˆØ±Ø©

**Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¬Ù…:**
```
Input: (batch, 1, 64, 64)
After Conv1: (batch, 32, 64, 64)
```
Ø§Ù„ØµÙŠØºØ©: `output_size = (input_size + 2*padding - kernel_size) / stride + 1`
```
(64 + 2*1 - 3) / 1 + 1 = 64
```

**Ù„Ù…Ø§Ø°Ø§ padding=1ØŸ**
- Ø¨Ø¯ÙˆÙ† padding: Ø§Ù„ØµÙˆØ±Ø© ØªØµØºØ± Ø¨Ø¹Ø¯ ÙƒÙ„ convolution
- Ù…Ø¹ padding=1: Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¬Ù…
- **Ø§Ù„ÙØ§Ø¦Ø¯Ø©**: Ù†ØªØ­ÙƒÙ… ÙÙŠ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… ÙÙ‚Ø· Ø¹Ø¨Ø± pooling

#### MaxPool2d
```python
self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
```

**Ø§Ù„Ù…ÙÙ‡ÙˆÙ…:**
- **Ù…Ø§Ø°Ø§**: Ø£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ Ù…Ù† ÙƒÙ„ Ù†Ø§ÙØ°Ø© 2Ã—2
- **Ù„Ù…Ø§Ø°Ø§**:
  - ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… (downsampling)
  - ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ù…Ù„ Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠ
  - Translation invariance (Ù„Ø§ ÙŠÙ‡Ù… Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ù€ feature Ø¨Ø§Ù„Ø¶Ø¨Ø·)
  - ÙŠÙ‚Ù„Ù„ overfitting

**Ù…Ø«Ø§Ù„:**
```
Input:  [1 3]    Output: [3]
        [2 1]
```

**Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¬Ù…:**
```
After Conv1: (batch, 32, 64, 64)
After Pool: (batch, 32, 32, 32)
```

#### Conv2d Layer 2
```python
self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
```

**Ù„Ù…Ø§Ø°Ø§ 64 filtersØŸ**
- Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£ÙˆÙ„Ù‰: ØªÙƒØªØ´Ù features Ø¨Ø³ÙŠØ·Ø© (Ø­ÙˆØ§ÙØŒ Ø²ÙˆØ§ÙŠØ§)
- Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©: ØªÙƒØªØ´Ù features Ù…Ø¹Ù‚Ø¯Ø© (Ø£Ø´ÙƒØ§Ù„ØŒ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ù† Ø£Ø­Ø±Ù)
- **Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ø¯Ø¯**: ÙŠØ³Ù…Ø­ Ø¨ØªØ¹Ù„Ù… patterns Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹

**Ø­Ø³Ø§Ø¨ Ø§Ù„Ø­Ø¬Ù…:**
```
After Pool1: (batch, 32, 32, 32)
After Conv2: (batch, 64, 32, 32)
After Pool2: (batch, 64, 16, 16)
```

#### Fully Connected Layer 1
```python
self.fc1 = nn.Linear(64 * 16 * 16, 256)
```

**Ù„Ù…Ø§Ø°Ø§ 64 * 16 * 16ØŸ**
- Ø¨Ø¹Ø¯ Conv2 + Pool2: (64, 16, 16)
- Ù†Ø­ØªØ§Ø¬ "ØªØ³Ø·ÙŠØ­" (flatten): 64 Ã— 16 Ã— 16 = 16,384
- **FC1**: ØªØ­ÙˆÙ„ Ù…Ù† 16,384 Ø¥Ù„Ù‰ 256

**Ø¯ÙˆØ± FC layers:**
- **Convolutions**: ØªØ³ØªØ®Ø±Ø¬ features
- **FC layers**: ØªØ¬Ù…Ø¹ Ø§Ù„Ù€ features ÙˆØªØªØ®Ø° Ø§Ù„Ù‚Ø±Ø§Ø±

#### Dropout
```python
self.dropout = nn.Dropout(0.5)
```

**Ø§Ù„Ù…ÙÙ‡ÙˆÙ…:**
- **Ù…Ø§Ø°Ø§**: Ø¥ÙŠÙ‚Ø§Ù 50% Ù…Ù† Ø§Ù„Ù€ neurons Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
- **Ù„Ù…Ø§Ø°Ø§**: 
  - ÙŠÙ…Ù†Ø¹ overfitting
  - ÙŠØ¬Ø¨Ø± Ø§Ù„Ø´Ø¨ÙƒØ© Ø¹Ù„Ù‰ ØªØ¹Ù„Ù… features redundant
  - ÙŠØ´Ø¨Ù‡ ensemble learning

**Ù…ØªÙ‰ ÙŠÙØ·Ø¨Ù‚ØŸ**
- **Training**: Ù†Ø¹Ù…
- **Evaluation**: Ù„Ø§ (Ù†Ø³ØªØ®Ø¯Ù… ÙƒÙ„ Ø§Ù„Ù€ neurons)

### ğŸ”„ Forward Pass

```python
def forward(self, x):
    # Conv block 1
    x = self.pool(F.relu(self.conv1(x)))  # (batch, 32, 32, 32)
    
    # Conv block 2
    x = self.pool(F.relu(self.conv2(x)))  # (batch, 64, 16, 16)
    
    # Flatten
    x = x.view(x.size(0), -1)  # (batch, 16384)
    
    # FC layers
    x = F.relu(self.fc1(x))  # (batch, 256)
    x = self.dropout(x)
    x = self.fc2(x)  # (batch, 36)
    
    return x
```

#### ReLU Activation
```python
F.relu(x)
```

**Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©:** `ReLU(x) = max(0, x)`

**Ù„Ù…Ø§Ø°Ø§ ReLUØŸ**
- **Ø¨Ø³ÙŠØ·Ø©**: Ø³Ù‡Ù„Ø© Ø§Ù„Ø­Ø³Ø§Ø¨
- **ØªØ­Ù„ Ù…Ø´ÙƒÙ„Ø©**: vanishing gradient
- **Non-linear**: ØªØ³Ù…Ø­ Ø¨ØªØ¹Ù„Ù… Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø¹Ù‚Ø¯Ø©

**Ø¨Ø¯Ø§Ø¦Ù„:**
- Sigmoid: `Ïƒ(x) = 1 / (1 + e^(-x))` (Ù‚Ø¯ÙŠÙ…Ø©ØŒ ØªØ¹Ø§Ù†ÙŠ Ù…Ù† vanishing gradient)
- Tanh: `tanh(x)` (Ø£ÙØ¶Ù„ Ù…Ù† sigmoid Ù„ÙƒÙ† Ø£Ø¨Ø·Ø£ Ù…Ù† ReLU)
- LeakyReLU: `max(0.01x, x)` (ØªØ­Ù„ Ù…Ø´ÙƒÙ„Ø© dying ReLU)

#### View (Flatten)
```python
x = x.view(x.size(0), -1)
```

**Ù…Ø§Ø°Ø§:**
- Ù…Ù† (batch, 64, 16, 16) Ø¥Ù„Ù‰ (batch, 16384)
- `-1`: Ø§Ø­Ø³Ø¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (16384)

**Ù„Ù…Ø§Ø°Ø§:**
- FC layers ØªØ­ØªØ§Ø¬ vector 1D
- Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ batch dimension

---

## 6. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ {#training}

### ğŸ¯ Loss Function

```python
criterion = nn.CrossEntropyLoss()
```

#### Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ:

**Cross-Entropy Loss:**
```
L = -Î£ y_true * log(y_pred)
```

**Ù„Ù…Ø§Ø°Ø§ Cross-EntropyØŸ**
- **Classification**: Ø§Ù„Ø£Ù†Ø³Ø¨ Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„ØªØµÙ†ÙŠÙ
- **Probabilistic**: ØªØ¹Ø§Ù…Ù„ Ø§Ù„Ù€ output ÙƒÙ€ probabilities
- **Gradient**: gradients ÙˆØ§Ø¶Ø­Ø© ÙˆØ³Ù‡Ù„Ø© Ø§Ù„Ø­Ø³Ø§Ø¨

**Ù…Ø§Ø°Ø§ ÙŠØ­Ø¯Ø« Ø¯Ø§Ø®Ù„ÙŠØ§Ù‹ØŸ**
1. ÙŠØ·Ø¨Ù‚ Softmax Ø¹Ù„Ù‰ Ø§Ù„Ù€ output
2. ÙŠØ­Ø³Ø¨ negative log-likelihood
3. ÙŠØ£Ø®Ø° Ø§Ù„Ù…ØªÙˆØ³Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù€ batch

**Softmax:**
```
softmax(x_i) = e^(x_i) / Î£ e^(x_j)
```

**Ù…Ø«Ø§Ù„:**
```
Logits: [2.0, 1.0, 0.1]
Softmax: [0.66, 0.24, 0.10]
True label: 0
Loss: -log(0.66) = 0.41
```

### ğŸ”§ Optimizer

```python
optimizer = optim.Adam(model.parameters(), lr=0.001)
```

#### Adam Optimizer

**Ù…Ø§ Ù‡Ùˆ AdamØŸ**
- **Adaptive Moment Estimation**
- ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ†:
  - **Momentum**: ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù€ gradients Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
  - **RMSprop**: ÙŠÙƒÙŠÙ learning rate Ù„ÙƒÙ„ parameter

**Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª:**
```
m_t = Î²1 * m_(t-1) + (1-Î²1) * g_t
v_t = Î²2 * v_(t-1) + (1-Î²2) * g_tÂ²
Î¸_t = Î¸_(t-1) - Î± * m_t / (âˆšv_t + Îµ)
```

**Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©:**
- `Î²1 = 0.9` (momentum)
- `Î²2 = 0.999` (RMSprop)
- `Îµ = 1e-8` (stability)

**Ù„Ù…Ø§Ø°Ø§ AdamØŸ**
- **Ø³Ø±ÙŠØ¹**: ÙŠØªÙ‚Ø§Ø±Ø¨ Ø£Ø³Ø±Ø¹ Ù…Ù† SGD
- **Adaptive**: learning rate Ù…Ø®ØªÙ„Ù Ù„ÙƒÙ„ parameter
- **Robust**: ÙŠØ¹Ù…Ù„ Ø¬ÙŠØ¯Ø§Ù‹ ÙÙŠ Ù…Ø¹Ø¸Ù… Ø§Ù„Ø­Ø§Ù„Ø§Øª

**Ø¨Ø¯Ø§Ø¦Ù„:**
- **SGD**: Ø£Ø¨Ø³Ø·ØŒ Ù„ÙƒÙ† Ø£Ø¨Ø·Ø£
- **SGD + Momentum**: Ø£Ø³Ø±Ø¹ Ù…Ù† SGD
- **RMSprop**: Ø¬ÙŠØ¯ Ù„Ù€ RNNs
- **AdamW**: Adam + weight decay (Ø£ÙØ¶Ù„ Ù„Ù„Ù€ regularization)

### ğŸ“‰ Learning Rate Scheduler

```python
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',
    factor=0.5,
    patience=2,
    verbose=True
)
```

#### Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:

- **`mode='min'`**: Ù†Ø±Ø§Ù‚Ø¨ loss (Ù†Ø±ÙŠØ¯Ù‡ ÙŠÙ†Ø®ÙØ¶)
- **`factor=0.5`**: Ù†Ù‚Ù„Ù„ LR Ø¨Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„Ù†ØµÙ
- **`patience=2`**: Ù†Ù†ØªØ¸Ø± 2 epochs Ù‚Ø¨Ù„ Ø§Ù„ØªÙ‚Ù„ÙŠÙ„
- **`verbose=True`**: Ø·Ø¨Ø§Ø¹Ø© Ø±Ø³Ø§Ù„Ø© Ø¹Ù†Ø¯ Ø§Ù„ØªÙ‚Ù„ÙŠÙ„

**Ù…Ø«Ø§Ù„:**
```
Epoch 1: loss = 0.5
Epoch 2: loss = 0.48
Epoch 3: loss = 0.47  â† ØªØ­Ø³Ù†
Epoch 4: loss = 0.47  â† Ù„Ø§ ØªØ­Ø³Ù† (1)
Epoch 5: loss = 0.47  â† Ù„Ø§ ØªØ­Ø³Ù† (2)
Epoch 6: LR = LR * 0.5  â† ØªÙ‚Ù„ÙŠÙ„!
```

**Ù„Ù…Ø§Ø°Ø§ØŸ**
- ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©: LR ÙƒØ¨ÙŠØ± â†’ Ø®Ø·ÙˆØ§Øª ÙƒØ¨ÙŠØ±Ø©
- Ø¹Ù†Ø¯ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø¨: LR ØµØºÙŠØ± â†’ Ø®Ø·ÙˆØ§Øª Ø¯Ù‚ÙŠÙ‚Ø©
- **Ø§Ù„Ù†ØªÙŠØ¬Ø©**: ØªÙ‚Ø§Ø±Ø¨ Ø£ÙØ¶Ù„

### ğŸ”„ Training Loop

```python
def train_epoch(model, data_loader, criterion, optimizer, device):
    model.train()  # Training mode
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    for images, labels in data_loader:
        images, labels = images.to(device), labels.to(device)
        
        # Zero gradients
        optimizer.zero_grad()
        
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
        
        # Backward pass
        loss.backward()
        optimizer.step()
        
        # Statistics
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()
    
    epoch_loss = running_loss / len(data_loader)
    epoch_acc = 100. * correct / total
    
    return epoch_loss, epoch_acc
```

#### Ø´Ø±Ø­ ÙƒÙ„ Ø®Ø·ÙˆØ©:

##### 1. `model.train()`
- **Ù…Ø§Ø°Ø§**: ØªÙØ¹ÙŠÙ„ training mode
- **Ø§Ù„ØªØ£Ø«ÙŠØ±**:
  - Dropout: ÙŠØ¹Ù…Ù„
  - BatchNorm: ÙŠØ­Ø¯Ø« Ø§Ù„Ù€ statistics

##### 2. `optimizer.zero_grad()`
- **Ù…Ø§Ø°Ø§**: ØªØµÙÙŠØ± Ø§Ù„Ù€ gradients
- **Ù„Ù…Ø§Ø°Ø§**: PyTorch ÙŠØ¬Ù…Ø¹ gradients Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
- **Ù…Ø§Ø°Ø§ Ù„Ùˆ Ù†Ø³ÙŠÙ†Ø§ØŸ**: gradients ØªØªØ±Ø§ÙƒÙ… â†’ Ù†ØªØ§Ø¦Ø¬ Ø®Ø§Ø·Ø¦Ø©

##### 3. Forward Pass
```python
outputs = model(images)
loss = criterion(outputs, labels)
```
- **outputs**: (batch_size, 36) logits
- **loss**: scalar value

##### 4. Backward Pass
```python
loss.backward()
```
- **Ù…Ø§Ø°Ø§**: Ø­Ø³Ø§Ø¨ gradients Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… backpropagation
- **ÙƒÙŠÙ**: Chain rule
- **Ø§Ù„Ù†ØªÙŠØ¬Ø©**: ÙƒÙ„ parameter ÙŠØ­ØµÙ„ Ø¹Ù„Ù‰ gradient

**Backpropagation Ù…Ø¨Ø³Ø·:**
```
âˆ‚L/âˆ‚w = âˆ‚L/âˆ‚y * âˆ‚y/âˆ‚w
```

##### 5. `optimizer.step()`
- **Ù…Ø§Ø°Ø§**: ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£ÙˆØ²Ø§Ù†
- **ÙƒÙŠÙ**: `w = w - lr * gradient`

##### 6. Statistics
```python
_, predicted = outputs.max(1)
correct += predicted.eq(labels).sum().item()
```
- `outputs.max(1)`: Ø£ÙƒØ¨Ø± Ù‚ÙŠÙ…Ø© ÙÙŠ ÙƒÙ„ ØµÙ
- `predicted.eq(labels)`: Ù…Ù‚Ø§Ø±Ù†Ø©
- `.sum().item()`: Ø¹Ø¯Ø¯ Ø§Ù„ØµØ­ÙŠØ­Ø©

### ğŸ“Š Validation

```python
def validate_epoch(model, data_loader, criterion, device):
    model.eval()  # Evaluation mode
    
    running_loss = 0.0
    correct = 0
    total = 0
    
    with torch.no_grad():  # No gradient computation
        for images, labels in data_loader:
            images, labels = images.to(device), labels.to(device)
            
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            running_loss += loss.item()
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()
    
    epoch_loss = running_loss / len(data_loader)
    epoch_acc = 100. * correct / total
    
    return epoch_loss, epoch_acc
```

#### Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¹Ù† Training:

##### 1. `model.eval()`
- **Dropout**: Ù…Ø¹Ø·Ù„
- **BatchNorm**: ÙŠØ³ØªØ®Ø¯Ù… running statistics

##### 2. `torch.no_grad()`
- **Ù…Ø§Ø°Ø§**: ØªØ¹Ø·ÙŠÙ„ Ø­Ø³Ø§Ø¨ gradients
- **Ù„Ù…Ø§Ø°Ø§**:
  - Ù†ÙˆÙØ± Ø°Ø§ÙƒØ±Ø©
  - Ù†Ø³Ø±Ø¹ Ø§Ù„Ø­Ø³Ø§Ø¨
  - Ù„Ø§ Ù†Ø­ØªØ§Ø¬ gradients ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…

##### 3. Ù„Ø§ `optimizer.step()`
- Ù„Ø§ Ù†Ø­Ø¯Ø« Ø§Ù„Ø£ÙˆØ²Ø§Ù† ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…

---

## 7. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… {#evaluation}

### ğŸ“ˆ Training History

```python
history = {
    'train_loss': [],
    'train_acc': [],
    'test_loss': [],
    'test_acc': []
}
```

### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬

```
Epoch 1/10
Train Loss: 0.6162 | Train Acc: 82.36%
Test Loss:  0.0679 | Test Acc:  97.52%

Epoch 10/10
Train Loss: 0.0698 | Train Acc: 97.35%
Test Loss:  0.0328 | Test Acc:  98.02%

Best Test Accuracy: 98.51% (Epoch 7)
```

### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:

#### Ù…Ù„Ø§Ø­Ø¸Ø§Øª:
1. **Test Acc > Train Acc ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©**
   - **ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ** Ø¹Ø§Ø¯Ø©Ù‹
   - **Ø§Ù„Ø³Ø¨Ø¨ Ø§Ù„Ù…Ø­ØªÙ…Ù„**: 
     - Dropout ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
     - Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø£Ø³Ù‡Ù„
     - Ø­Ø¬Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ØµØºÙŠØ±

2. **Ø§Ù„ØªÙ‚Ø§Ø±Ø¨ Ø§Ù„Ø³Ø±ÙŠØ¹**
   - Ù…Ù† 82% Ø¥Ù„Ù‰ 97% ÙÙŠ epoch ÙˆØ§Ø­Ø¯
   - **Ø§Ù„Ø³Ø¨Ø¨**: Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø¨Ø³ÙŠØ·Ø© Ù†Ø³Ø¨ÙŠØ§Ù‹

3. **Best ÙÙŠ Epoch 7**
   - Ø¨Ø¹Ø¯Ù‡Ø§ Ø¨Ø¯Ø£ overfitting Ø®ÙÙŠÙ
   - **Ø§Ù„Ø­Ù„**: Early stopping

### ğŸ“‰ Loss Curve Analysis

**Loss Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹ (0.0328)**
- **Ø¬ÙŠØ¯**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø«Ù‚ Ù…Ù† ØªÙ†Ø¨Ø¤Ø§ØªÙ‡
- **ØªØ­Ø°ÙŠØ±**: Ù‚Ø¯ ÙŠÙƒÙˆÙ† overconfident

**Train Loss < Test Loss**
- **Ø·Ø¨ÙŠØ¹ÙŠ**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªØ¹Ù„Ù… Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨

---

## 8. Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ ÙˆØ§Ù„ØªÙ†Ø¨Ø¤ {#inference}

### ğŸ”® Prediction Function

```python
def predict_image(image_path, model, transform, device, class_names):
    # Load image
    image = Image.open(image_path).convert('L')
    image_tensor = transform(image).unsqueeze(0).to(device)
    
    # Set to eval mode
    model.eval()
    
    # Predict
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = F.softmax(output, dim=1)
        confidence, predicted = torch.max(probabilities, 1)
    
    predicted_class = class_names[predicted.item()]
    confidence_score = confidence.item() * 100
    
    return predicted_class, confidence_score
```

#### Ø´Ø±Ø­ Ø§Ù„Ø®Ø·ÙˆØ§Øª:

##### 1. `unsqueeze(0)`
- **Ù…Ø§Ø°Ø§**: Ø¥Ø¶Ø§ÙØ© batch dimension
- **Ù…Ù†**: (1, 64, 64)
- **Ø¥Ù„Ù‰**: (1, 1, 64, 64)
- **Ù„Ù…Ø§Ø°Ø§**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªÙˆÙ‚Ø¹ batch

##### 2. `F.softmax(output, dim=1)`
- **Ù…Ø§Ø°Ø§**: ØªØ­ÙˆÙŠÙ„ logits Ø¥Ù„Ù‰ probabilities
- **Ù…Ù†**: [-âˆ, +âˆ]
- **Ø¥Ù„Ù‰**: [0, 1] (Ù…Ø¬Ù…ÙˆØ¹Ù‡Ø§ = 1)

##### 3. `torch.max(probabilities, 1)`
- **Returns**: (max_value, max_index)
- **max_value**: Ø§Ù„Ø«Ù‚Ø© (confidence)
- **max_index**: Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©

---

## 9. Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© {#mistakes}

### âŒ 1. Ù†Ø³ÙŠØ§Ù† `model.eval()`
```python
# Ø®Ø·Ø£
with torch.no_grad():
    output = model(image)

# ØµØ­ÙŠØ­
model.eval()
with torch.no_grad():
    output = model(image)
```

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©**: Dropout Ø³ÙŠØ¹Ù…Ù„ â†’ Ù†ØªØ§Ø¦Ø¬ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©

### âŒ 2. Ù†Ø³ÙŠØ§Ù† `optimizer.zero_grad()`
```python
# Ø®Ø·Ø£
for images, labels in loader:
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()

# ØµØ­ÙŠØ­
for images, labels in loader:
    optimizer.zero_grad()  # â† Ù‡Ù†Ø§!
    outputs = model(images)
    loss = criterion(outputs, labels)
    loss.backward()
    optimizer.step()
```

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©**: Gradients ØªØªØ±Ø§ÙƒÙ… â†’ ØªØ­Ø¯ÙŠØ«Ø§Øª Ø®Ø§Ø·Ø¦Ø©

### âŒ 3. Ø§Ø³ØªØ®Ø¯Ø§Ù… Softmax Ù‚Ø¨Ù„ CrossEntropyLoss
```python
# Ø®Ø·Ø£
output = F.softmax(model(x), dim=1)
loss = criterion(output, labels)

# ØµØ­ÙŠØ­
output = model(x)  # logits ÙÙ‚Ø·
loss = criterion(output, labels)
```

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©**: CrossEntropyLoss ÙŠØ·Ø¨Ù‚ softmax Ø¯Ø§Ø®Ù„ÙŠØ§Ù‹ â†’ double softmax

### âŒ 4. Ù†Ø³ÙŠØ§Ù† `.to(device)`
```python
# Ø®Ø·Ø£
images, labels = next(iter(loader))
outputs = model(images)

# ØµØ­ÙŠØ­
images, labels = images.to(device), labels.to(device)
outputs = model(images)
```

**Ø§Ù„Ù…Ø´ÙƒÙ„Ø©**: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ CPU ÙˆØ§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ GPU â†’ Ø®Ø·Ø£

### âŒ 5. Overfitting Ø¹Ù„Ù‰ Training Set
**Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶:**
- Train Acc = 100%
- Test Acc = 70%

**Ø§Ù„Ø­Ù„ÙˆÙ„:**
- Dropout
- Data Augmentation
- Early Stopping
- Regularization (L1/L2)

---

## 10. Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª {#best-practices}

### âœ… 1. Ø§Ø³ØªØ®Ø¯Ø§Ù… Config Dictionary
```python
CONFIG = {
    'batch_size': 32,
    'learning_rate': 0.001,
    ...
}
```

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„
- ÙˆØ¶ÙˆØ­ Ø§Ù„ÙƒÙˆØ¯
- Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø­ÙØ¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

### âœ… 2. Random Seeds Ù„Ù„Ù€ Reproducibility
```python
torch.manual_seed(42)
np.random.seed(42)
```

### âœ… 3. Ø§Ø³ØªØ®Ø¯Ø§Ù… DataLoader
```python
loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)
```

**Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù†:**
```python
for i in range(0, len(dataset), batch_size):
    batch = dataset[i:i+batch_size]
```

### âœ… 4. Progress Bars
```python
from tqdm.auto import tqdm
for images, labels in tqdm(loader):
    ...
```

### âœ… 5. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
```python
torch.save({
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': loss,
}, 'checkpoint.pth')
```

### âœ… 6. Early Stopping
```python
best_acc = 0
patience = 5
counter = 0

for epoch in range(num_epochs):
    val_acc = validate(...)
    
    if val_acc > best_acc:
        best_acc = val_acc
        counter = 0
        save_model()
    else:
        counter += 1
        if counter >= patience:
            print("Early stopping!")
            break
```

---

## 11. Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© {#improvements}

### ğŸš€ 1. Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø£Ø¹Ù…Ù‚

#### Ø§Ù„Ø­Ø§Ù„ÙŠ:
```
Conv1 â†’ Pool â†’ Conv2 â†’ Pool â†’ FC
```

#### Ø§Ù„Ù…Ù‚ØªØ±Ø­:
```
Conv1 â†’ Conv2 â†’ Pool â†’ Conv3 â†’ Conv4 â†’ Pool â†’ FC
```

**Ø§Ù„ÙƒÙˆØ¯:**
```python
class DeepOCRCNN(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)
        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 16 * 16, 512)
        self.fc2 = nn.Linear(512, num_classes)
        self.dropout = nn.Dropout(0.5)
    
    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(F.relu(self.conv2(x)))
        x = F.relu(self.conv3(x))
        x = self.pool(F.relu(self.conv4(x)))
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x
```

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- ØªØ¹Ù„Ù… features Ø£ÙƒØ«Ø± ØªØ¹Ù‚ÙŠØ¯Ø§Ù‹
- Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰

**Ø§Ù„Ø¹ÙŠÙˆØ¨:**
- Ø­Ù…Ù„ Ø­Ø³Ø§Ø¨ÙŠ Ø£ÙƒØ¨Ø±
- Ù‚Ø¯ ÙŠØ­Ø¯Ø« overfitting

### ğŸš€ 2. Batch Normalization

```python
class OCRCNN_BN(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
        self.bn1 = nn.BatchNorm2d(32)  # â† Ù‡Ù†Ø§
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.bn2 = nn.BatchNorm2d(64)  # â† Ù‡Ù†Ø§
        ...
    
    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        ...
```

**Ù…Ø§ Ù‡Ùˆ BatchNormØŸ**
- ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù€ activations ÙÙŠ ÙƒÙ„ batch
- `output = (input - mean) / std`

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø±Ø¹
- ÙŠØ³Ù…Ø­ Ø¨Ù€ learning rates Ø£ÙƒØ¨Ø±
- ÙŠÙ‚Ù„Ù„ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù€ Dropout
- ÙŠØ­Ø³Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±

### ğŸš€ 3. Data Augmentation

```python
train_transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.Grayscale(1),
    transforms.RandomRotation(10),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
```

**ØªÙ‚Ù†ÙŠØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©:**
- `RandomPerspective`: ØªØºÙŠÙŠØ± Ø§Ù„Ù…Ù†Ø¸ÙˆØ±
- `ColorJitter`: ØªØºÙŠÙŠØ± Ø§Ù„Ø³Ø·ÙˆØ¹/Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Ù„Ù„ØµÙˆØ± Ø§Ù„Ù…Ù„ÙˆÙ†Ø©)
- `RandomErasing`: Ø­Ø°Ù Ø£Ø¬Ø²Ø§Ø¡ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©

### ğŸš€ 4. Transfer Learning

```python
import torchvision.models as models

# Ø§Ø³ØªØ®Ø¯Ø§Ù… ResNet Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ø§Ù‹
resnet = models.resnet18(pretrained=True)

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ù€ grayscale
resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)

# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
num_features = resnet.fc.in_features
resnet.fc = nn.Linear(num_features, 36)
```

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø±Ø¹
- Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰ (Ø®Ø§ØµØ© Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ù„ÙŠÙ„Ø©)
- ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† features Ù…Ø¯Ø±Ø¨Ø© Ø¹Ù„Ù‰ ImageNet

### ğŸš€ 5. Learning Rate Scheduling

```python
# Cosine Annealing
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)

# Step LR
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

# Exponential LR
scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)
```

### ğŸš€ 6. Mixed Precision Training

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for images, labels in loader:
    optimizer.zero_grad()
    
    with autocast():  # â† Ø§Ø³ØªØ®Ø¯Ø§Ù… FP16
        outputs = model(images)
        loss = criterion(outputs, labels)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- ØªØ¯Ø±ÙŠØ¨ Ø£Ø³Ø±Ø¹ (2x)
- Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø°Ø§ÙƒØ±Ø© Ø£Ù‚Ù„
- Ù†ÙØ³ Ø§Ù„Ø¯Ù‚Ø© ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹

---

## 12. Ù…Ù„Ø®Øµ Pipeline {#pipeline}

### ğŸ“Š Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      1. DATA LOADING                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Raw Images (PNG) â†’ ImageFolder â†’ Dataset                   â”‚
â”‚   â†“                                                         â”‚
â”‚ Transforms:                                                 â”‚
â”‚   - Resize(64Ã—64)                                          â”‚
â”‚   - Grayscale                                              â”‚
â”‚   - ToTensor                                               â”‚
â”‚   - Normalize                                              â”‚
â”‚   â†“                                                         â”‚
â”‚ Tensor: (batch, 1, 64, 64)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      2. MODEL                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: (batch, 1, 64, 64)                                  â”‚
â”‚   â†“                                                         â”‚
â”‚ Conv1(32) + ReLU + MaxPool â†’ (batch, 32, 32, 32)          â”‚
â”‚   â†“                                                         â”‚
â”‚ Conv2(64) + ReLU + MaxPool â†’ (batch, 64, 16, 16)          â”‚
â”‚   â†“                                                         â”‚
â”‚ Flatten â†’ (batch, 16384)                                   â”‚
â”‚   â†“                                                         â”‚
â”‚ FC1(256) + ReLU + Dropout                                  â”‚
â”‚   â†“                                                         â”‚
â”‚ FC2(36) â†’ Logits                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      3. TRAINING                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ For each epoch:                                            â”‚
â”‚   For each batch:                                          â”‚
â”‚     1. Forward Pass â†’ outputs                              â”‚
â”‚     2. Compute Loss (CrossEntropy)                         â”‚
â”‚     3. Backward Pass â†’ gradients                           â”‚
â”‚     4. Update Weights (Adam)                               â”‚
â”‚   Validate on test set                                     â”‚
â”‚   Update LR (ReduceLROnPlateau)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      4. INFERENCE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ New Image â†’ Transform â†’ Tensor                             â”‚
â”‚   â†“                                                         â”‚
â”‚ Model(eval mode) â†’ Logits                                  â”‚
â”‚   â†“                                                         â”‚
â”‚ Softmax â†’ Probabilities                                    â”‚
â”‚   â†“                                                         â”‚
â”‚ argmax â†’ Predicted Class + Confidence                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”„ Training Loop Detailed

```
Epoch 1:
  â”œâ”€ Batch 1:
  â”‚    â”œâ”€ Load 32 images
  â”‚    â”œâ”€ Forward: images â†’ outputs
  â”‚    â”œâ”€ Loss: CrossEntropy(outputs, labels)
  â”‚    â”œâ”€ Backward: loss.backward()
  â”‚    â””â”€ Update: optimizer.step()
  â”œâ”€ Batch 2:
  â”‚    â””â”€ ... (repeat)
  â”œâ”€ ...
  â”œâ”€ Batch 642:
  â”‚    â””â”€ ... (last batch)
  â”œâ”€ Compute Train Metrics
  â”œâ”€ Validate on Test Set
  â””â”€ Update Learning Rate

Epoch 2:
  â””â”€ ... (repeat)
```

---

## 13. Ù†Ø­Ùˆ Ù†Ø¸Ø§Ù… OCR Ø¥Ù†ØªØ§Ø¬ÙŠ {#production}

### ğŸ­ Ù…Ù† Notebook Ø¥Ù„Ù‰ Production

#### 1. **ÙØµÙ„ Ø§Ù„ÙƒÙˆØ¯**

```
ocr_project/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ dataset.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ocr_cnn.py
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ predictor.py
â”œâ”€â”€ api/
â”‚   â””â”€â”€ app.py
â””â”€â”€ requirements.txt
```

#### 2. **API Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… FastAPI**

```python
from fastapi import FastAPI, File, UploadFile
from PIL import Image
import io

app = FastAPI()

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    # Read image
    image = Image.open(io.BytesIO(await file.read()))
    
    # Predict
    predicted_class, confidence = predictor.predict(image)
    
    return {
        "class": predicted_class,
        "confidence": confidence
    }
```

#### 3. **Docker Container**

```dockerfile
FROM python:3.9

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["uvicorn", "api.app:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 4. **Model Optimization**

##### Quantization
```python
# ØªØ­ÙˆÙŠÙ„ FP32 Ø¥Ù„Ù‰ INT8
quantized_model = torch.quantization.quantize_dynamic(
    model, {nn.Linear, nn.Conv2d}, dtype=torch.qint8
)
```

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- Ø­Ø¬Ù… Ø£ØµØºØ± (4x)
- Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø£Ø³Ø±Ø¹ (2-4x)
- Ø¯Ù‚Ø© Ù‚Ø±ÙŠØ¨Ø© (ÙÙ‚Ø¯Ø§Ù† 1-2%)

##### ONNX Export
```python
# ØªØµØ¯ÙŠØ± Ù„Ù€ ONNX
dummy_input = torch.randn(1, 1, 64, 64)
torch.onnx.export(model, dummy_input, "model.onnx")
```

**Ø§Ù„ÙÙˆØ§Ø¦Ø¯:**
- ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ Ø£ÙŠ framework
- ØªØ­Ø³ÙŠÙ†Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
- deployment Ø£Ø³Ù‡Ù„

#### 5. **Monitoring & Logging**

```python
import logging
from prometheus_client import Counter, Histogram

# Metrics
predictions_total = Counter('predictions_total', 'Total predictions')
prediction_time = Histogram('prediction_time', 'Prediction time')

# Logging
logger = logging.getLogger(__name__)

@prediction_time.time()
def predict(image):
    predictions_total.inc()
    logger.info(f"Predicting image...")
    result = model(image)
    logger.info(f"Result: {result}")
    return result
```

#### 6. **A/B Testing**

```python
def predict_with_ab_test(image, user_id):
    # 50% users get model v1, 50% get model v2
    if hash(user_id) % 2 == 0:
        return model_v1.predict(image)
    else:
        return model_v2.predict(image)
```

#### 7. **Continuous Training**

```python
# ÙƒÙ„ Ø£Ø³Ø¨ÙˆØ¹: ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
def retrain_model():
    # Load new data
    new_data = load_new_data()
    
    # Fine-tune existing model
    model.load_state_dict(torch.load('best_model.pth'))
    train(model, new_data, epochs=5)
    
    # Evaluate
    if new_acc > old_acc:
        save_model(model, 'best_model.pth')
```

#### 8. **Scalability**

```yaml
# Kubernetes deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ocr-api
spec:
  replicas: 3  # 3 instances
  template:
    spec:
      containers:
      - name: ocr
        image: ocr-api:latest
        resources:
          limits:
            memory: "2Gi"
            cpu: "1000m"
```

---

## ğŸ“ Ø§Ù„Ø®Ù„Ø§ØµØ©

### Ù…Ø§ ØªØ¹Ù„Ù…Ù†Ø§Ù‡:

1. **Data Pipeline**: 
   - ImageFolder, Transforms, DataLoader
   - Normalization, Augmentation

2. **CNN Architecture**:
   - Convolution, Pooling, FC layers
   - ReLU, Dropout, Softmax

3. **Training**:
   - Loss functions (CrossEntropy)
   - Optimizers (Adam)
   - Learning rate scheduling

4. **Best Practices**:
   - Config dictionaries
   - Random seeds
   - Model checkpointing

5. **Production**:
   - API development
   - Model optimization
   - Monitoring

### ğŸ“š Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØ¹Ù„Ù…:

1. **Deep Learning Book** - Ian Goodfellow
2. **CS231n** - Stanford (CNNs)
3. **PyTorch Documentation**
4. **Papers with Code** - Ø£Ø­Ø¯Ø« Ø§Ù„Ø£Ø¨Ø­Ø§Ø«

### ğŸš€ Ø§Ù„ØªØ­Ø¯ÙŠØ§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:

1. Ø­Ø§ÙˆÙ„ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø© Ø¥Ù„Ù‰ 99%+
2. Ø£Ø¶Ù support Ù„Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
3. Ø¨Ù†Ø§Ø¡ web app ÙƒØ§Ù…Ù„
4. ØªØ¬Ø±Ø¨Ø© architectures Ù…Ø®ØªÙ„ÙØ© (ResNet, VGG)
5. ØªØ·Ø¨ÙŠÙ‚ Transfer Learning

---

**Ø¨Ø§Ù„ØªÙˆÙÙŠÙ‚ ÙÙŠ Ø±Ø­Ù„ØªÙƒ ÙÙŠ Deep Learning! ğŸ‰**
